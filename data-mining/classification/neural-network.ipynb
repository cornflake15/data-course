{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit",
      "language": "python",
      "name": "python38364bitf33250e8650946d19caa144309e3c9fe"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "neural-network.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cornflake15/data-course/blob/mining/data-mining/classification/neural-network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u77ZhCtYXSw"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAY55JzmYXSy"
      },
      "source": [
        "Implementasi algoritma Artificial Neural Network menggunakan Keras dan Tensorflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORoUlU8wYXSz"
      },
      "source": [
        "## 1. Pendahuluan\n",
        "\n",
        "**Tensorflow** adalah platform/framework untuk membangun sebuah model machine learning yang bersifat open source. Tensorflow menyediakan fitur end-to-end / full stack development, dari prototyping hingga deployment model machine learning ke dalam aplikasi.\n",
        "\n",
        "**Keras** adalah high-level API untuk mengimplementasikan Deep Learning pada platform Tensorflow. Sehingga developer/engineer bisa fokus terhadap pemodelan machine learningnya daripada cara memprogram model machine learning.\n",
        "\n",
        "Install terlebih dahulu modul Tensorflow: \n",
        "\n",
        "`pip install tensorflow`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l04B-QbdYXSz"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7dmp-wMYXS0"
      },
      "source": [
        "### 1.1 Inisialisasi model\n",
        "\n",
        "Di bagian ini kita akan membangun model neural network yang paling sederhana, terdiri 1 input layer, 1 neuron, dan 1 layer output. Untuk mengimplementasikan ini kita bisa memanfaatkan kelas **`keras`** dari modul **`tensorflow`**. Kemudian memanggil method **`Sequential`** untuk mendefinisikan arsitektur neural networknya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1ivWjTiYXS0"
      },
      "source": [
        "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyfOC2yOYXS1"
      },
      "source": [
        "Di dalam method Sequential kita bisa mendefinisikan tumpukan layer-layer penyusun model dengan mengimplementasikan kelas **`keras.layers.Dense()`**. Untuk lebih lengkap mengenai method `Sequential` bisa dilihat pada [dokumentasinya](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential?version=nightly)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExWikhzNYXS1"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eJbh6f7YXS1"
      },
      "source": [
        "Selanjutnya adalah mengimplementasikan fungsi optimasi dengan memanggil method **`compile`** melalui objek **`model`**. Di dalamnya kita definisikan atribut **`optimizer`** dan juga **`loss`** function yang digunakan. Jenis-jenis [fungsi optimasi](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers?version=nightly) dan [loss function](https://www.tensorflow.org/api_docs/python/tf/keras/losses) bisa langsung dibaca di dokumentasi resminya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PVBAdmhYXS1"
      },
      "source": [
        "### 1.2 Dataset\n",
        "\n",
        "Di bagian ini kita akan membuat dataset sederhana dalam bentuk array 1 dimensi menggunakan **`numpy`**. Data disimpan pada objek **`X`** dan label pada objek **`y`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypn05d2RYXS2"
      },
      "source": [
        "X = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "y = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oavt6mhwYXS2"
      },
      "source": [
        "### 1.3 Fitting\n",
        "\n",
        "Setelah mempersiapkan dataset (*biasanya proses pre-processing dataset adalah proses yang panjang, bahkan lebih panjang dari proses pemodelan neural networknya. Namun sebagai permulaan di bagian ini belum membahas pre-processing*) hal selanjutnya dilakukan adalah fitting dataset ke dalam model.\n",
        "\n",
        "Proses fitting diimplementasikan dengan memanggil method **`fit()`** melalui objek **`model`**. Method `fit()` menerima parameter input data, label data, dan epoch. Epoch mengacu pada satu kali putaran (_cycle_) untuk mendistribusikan seluruh dataset ke dalam model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4GNyTd1YXS2",
        "outputId": "e125fca7-0bb2-4d15-fa66-0253acfbe71f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X, y, epochs=10) # input data (X), label data (y), dan epoch (epochs)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 5.0150\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.1204\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4130\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.8529\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.4088\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.0560\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.7752\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5510\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3714\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2271\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f79500946a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dty3qTUKYXS2"
      },
      "source": [
        "### 1.4 Prediksi\n",
        "\n",
        "Setelah model di-training hal selanjutnya adalah melakukan prediksi. Implementasinya dapat dilakukan dengan memanggil method **`predict`** berdasarkan objek `model`, kemudian memasukkan nilai yang akan diprediksi ke dalam method tersebut. Seperti terlihat pada output di bawah, berapakah hasil prediksi untuk nilai input 10.0?. Anda bisa mencoba nilai lainnya untuk diprediksi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3yPl-lCYXS3",
        "outputId": "7e492695-93eb-4ebe-b5d2-2c0f3a9a613d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model.predict([10.0]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[13.943926]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTokBNt4YXS3"
      },
      "source": [
        "## Contoh 1\n",
        "\n",
        "Pada bagian ini adalah implementasi neural network berdasarkan studi kasus materi [Neural Network Demystified](https://www.youtube.com/playlist?list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU) dengan Tensorflow. Pada contoh tersebut terdapat dua atribut yaitu \"Hour of Study\" dan \"Hour of Sleep\", dan satu output yaitu \"Test Score\". Contoh data dapat dilihat pada tabel di bawah.\n",
        "\n",
        "|Hour of Study|Hour of Sleep|Test Score|\n",
        "|-------------|-------------|----------|\n",
        "|3|5|75|\n",
        "|5|1|82|\n",
        "|10|2|93|\n",
        "|3|2|60|\n",
        "|4|3|63|\n",
        "|6|7|94|\n",
        "|8|10|97|\n",
        "\n",
        "Data tersebut disimpan ke dalam struktur data numpy array dua dimensi (untuk atribut/fitur) dan numpy array satu dimensi untuk output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9H6DQdDYXS3"
      },
      "source": [
        "X = np.array([[3, 5], [5, 1], [10, 2], [3, 2], [4, 3], [6, 7], [8, 10]]) # Input\n",
        "y = np.array([75, 82, 93, 60, 63, 94, 97]) # Output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ceOHA6_LYXS3",
        "outputId": "b6d67d03-9329-4c8d-f4f3-71befbc31a98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X.shape) # Dimensi array Input\n",
        "print(y.shape) # Dimensi array Output"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7, 2)\n",
            "(7,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqOgtX2TYXS3"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "Di bagian ini kita cukup melakukan pre-processing dengan teknik `scaling` saja, karena datasetnya hanya bertipe numerikal. Scaling diimplementasikan dengan kelas **`StandardScaler`** pada modul **`sklearn.preprocessing`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZSOAx8vYXS4"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scale = scaler.fit_transform(X)\n",
        "y_scale = scaler.fit_transform(y.reshape(-1, 1))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T7Gbr7LYXS4"
      },
      "source": [
        "### Modeling\n",
        "\n",
        "Model neural network yang akan diimplementasikan berdasarkan gambar berikut ini:\n",
        "![model](https://github.com/cornflake15/data-course/blob/main/data-mining/classification/img/model-1.png?raw=1)\n",
        "\n",
        "Kemudian kita bisa me-review model yang kita buat dengan memanggil method **`summary()`** pada objek **`model`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "phdUJyWdYXS5",
        "outputId": "d7b95f48-9607-4321-9c5a-22893bad5afc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(2, input_shape=(2,)),\n",
        "    keras.layers.Dense(3, activation='sigmoid'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 9         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 19\n",
            "Trainable params: 19\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gp5KDFVYXS5"
      },
      "source": [
        "### Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Hgy1JyONYXS5",
        "outputId": "81385c57-38a5-4b7a-ea01-17759cb430e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X, y, epochs=200)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 6607.3599\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6135.4731\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5522.5850\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4906.9009\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4358.4561\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3873.9011\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3445.7522\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3067.4392\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2733.1619\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2437.7942\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2176.8069\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1946.1986\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1742.4330\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1562.3857\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1403.2958\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1262.7244\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1138.5149\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1028.7635\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 931.7871\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 846.0990\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 770.3846\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 703.4837\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 644.3698\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 592.1366\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 545.9833\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 505.2021\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 469.1678\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 437.3279\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 409.1939\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 384.3346\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 362.3689\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 342.9598\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 325.8096\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 310.6557\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 297.2655\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 285.4337\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 274.9789\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 265.7407\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 257.5776\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 250.3642\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 243.9903\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 238.3579\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 233.3806\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 228.9823\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 225.0955\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 221.6604\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 218.6246\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 215.9413\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 213.5695\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 211.4729\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 209.6190\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 207.9796\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 206.5295\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 205.2461\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 204.1098\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 203.1027\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 202.2090\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 201.4143\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 200.7053\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 200.0696\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 199.4937\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 198.9628\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 198.4556\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 197.9323\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 197.2892\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 196.1019\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 190.9222\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 624.5626\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.9262\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.8968\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.8707\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.8477\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.8274\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 195.8095\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.7936\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.7796\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.7671\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.7562\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.7465\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.7380\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 195.7304\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.7237\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.7178\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.7126\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 195.7080\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.7040\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.7004\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6972\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6944\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6918\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6897\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.6877\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6861\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.6845\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 195.6832\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6820\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.6810\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6801\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.6792\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6785\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 195.6779\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 195.6773\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.6768\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6763\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 195.6760\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.6757\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.6754\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6750\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 195.6748\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 195.6746\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.6745\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.6743\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.6742\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6740\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6740\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6738\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 195.6737\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6736\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6736\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 195.6735\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6735\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6734\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6733\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6733\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 195.6733\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6733\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.6732\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6731\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 195.6732\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6732\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.6732\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.6732\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 195.6731\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6731\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6731\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6731\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6730\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.6731\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 195.6730\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6731\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6731\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6731\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 195.6731\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.6731\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.6731\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.6731\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.6731\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.6731\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6731\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6731\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6731\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6731\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6731\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6731\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6731\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6730\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.6730\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.6731\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6731\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.6730\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6730\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 195.6730\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6731\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6731\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 195.6730\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6730\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 195.6730\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6731\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 195.6730\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6730\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 195.6730\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6730\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 195.6730\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6730\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 195.6730\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 195.6730\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 195.6731\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 195.6730\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6730\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 195.6730\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 195.6730\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 195.6731\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.6730\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6731\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.6731\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.6731\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6731\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6731\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6730\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.6731\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6730\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6731\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6730\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.6730\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 195.6730\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 195.6730\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6730\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 195.6730\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 195.6730\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.6730\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f78e9878588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjGkeASCYXS5"
      },
      "source": [
        "### Prediksi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qw1W3_Y_YXS5",
        "outputId": "b6145a87-31f7-4981-ca54-25f39645d649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model.predict([[5, 5]]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[80.571304]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAwuQ19xYXS6"
      },
      "source": [
        "##  Studi Kasus 1\n",
        "\n",
        "\n",
        "**Fashion MNIST**\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/cornflake15/data-course/blob/main/data-mining/classification/img/fashion-mnist-sprite.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
        "\n",
        "Fashion MNIST adalah dataset gambar pakaian sebanyak 70,0000 gambar dengan resolusi 28x28 pixel dengan rentang nilai 0 sampai dengan 255. Dataset ini terdiri dari 10 kategori (label) seperti tertera di tabel bawah ini.\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "Dataset ini sudah disediakan oleh Tensorflow sehingga kita tidak harus men-downloadnya secara terpisah. Dataset Fashion MNIST dapat di-download dengan memanggil modul **`tensorflow.keras.datasets.fashion_minist`**. \n",
        "\n",
        "Domain permasalahan yang bisa dipecahkan oleh neural network pada dataset ini adalah klasifikasi, sehingga kita harus memisahkan antara dataset yang digunakan untuk training dan dataset yang digunakan untuk testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEghKNgUYXS6",
        "outputId": "b4f1647c-1f9b-41f6-f657-94557e9e2f92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist # download dataset\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data() # memisahkan dataset menjadi training dan testing"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKDfIvVBYXS7"
      },
      "source": [
        "**Tampilkan Contoh Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KDkzV10YXS7",
        "outputId": "7b29cccd-5094-4430-8f90-fcab7b429929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.set_printoptions(linewidth=200)\n",
        "plt.imshow(training_images[0])\n",
        "print(training_images[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2sEEiSCYXS7"
      },
      "source": [
        "**Normalisasi Data**\n",
        "\n",
        "Ini adalah tahap pre-processing data dengan cara menormalisasi nilai setiap pixel dari gambar dengan cara membagi nilai tersebut dengan 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWEZ6eYuYXS7"
      },
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1UMrV0JYXS7",
        "outputId": "c1e9f7b6-b5f8-419d-9cb4-b31e3712b87c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Tampilkan data setelah dinormalisasi\n",
        "print(np.around(training_images[0], 2)) # Dibulatkan sebanyak 2 angka sebagai contoh saja"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.05 0.29 0.   0.   0.   0.02 0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.01 0.   0.14 0.53 0.5  0.24 0.21 0.   0.   0.   0.   0.01 0.02 0.   0.   0.01]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.02 0.   0.4  0.8  0.69 0.53 0.56 0.48 0.09 0.   0.   0.   0.   0.05 0.04 0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.61 0.93 0.81 0.7  0.42 0.61 0.63 0.43 0.25 0.09 0.3  0.51 0.28 0.06]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.27 0.81 0.87 0.85 0.85 0.85 0.64 0.5  0.47 0.48 0.57 0.55 0.35 0.67 0.26]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.78 0.91 0.91 0.91 0.9  0.87 0.87 0.84 0.84 0.64 0.5  0.48 0.77 0.9  0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.72 0.88 0.85 0.87 0.89 0.92 0.89 0.88 0.87 0.88 0.87 0.87 0.96 0.68 0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.76 0.89 0.85 0.84 0.78 0.71 0.83 0.82 0.83 0.84 0.87 0.86 0.95 0.79 0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.01 0.   0.05 0.86 0.86 0.83 0.85 0.75 0.66 0.89 0.82 0.85 0.88 0.83 0.89 0.77 0.82 0.2 ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.02 0.   0.39 0.96 0.87 0.86 0.85 0.8  0.78 0.87 0.84 0.84 0.87 0.86 0.96 0.47 0.65 0.22]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.02 0.   0.   0.22 0.93 0.89 0.9  0.89 0.94 0.91 0.84 0.85 0.87 0.92 0.85 0.85 0.82 0.36 0.  ]\n",
            " [0.   0.   0.   0.02 0.02 0.03 0.01 0.   0.   0.   0.   0.   0.93 0.89 0.85 0.87 0.87 0.86 0.87 0.87 0.85 0.87 0.9  0.84 0.85 1.   0.3  0.  ]\n",
            " [0.   0.01 0.   0.   0.   0.   0.   0.   0.   0.24 0.57 0.8  0.89 0.81 0.84 0.87 0.85 0.82 0.83 0.85 0.88 0.87 0.86 0.84 0.88 0.96 0.62 0.  ]\n",
            " [0.   0.   0.   0.   0.07 0.17 0.32 0.42 0.74 0.89 0.86 0.87 0.85 0.89 0.78 0.8  0.83 0.9  0.88 0.92 0.69 0.74 0.98 0.97 0.91 0.93 0.84 0.  ]\n",
            " [0.   0.22 0.73 0.82 0.88 0.87 0.88 0.82 0.8  0.84 0.82 0.82 0.78 0.62 0.96 0.76 0.81 0.87 1.   1.   0.87 0.92 0.87 0.83 0.86 0.91 0.96 0.  ]\n",
            " [0.01 0.79 0.89 0.88 0.87 0.83 0.83 0.84 0.8  0.8  0.8  0.86 0.94 0.31 0.59 1.   0.9  0.87 0.74 0.6  0.75 0.82 0.8  0.82 0.87 0.89 0.88 0.  ]\n",
            " [0.38 0.91 0.78 0.82 0.87 0.9  0.9  0.92 0.98 0.86 0.76 0.84 0.85 0.95 0.25 0.29 0.42 0.46 0.66 0.86 0.87 0.84 0.85 0.87 0.87 0.88 0.9  0.11]\n",
            " [0.29 0.8  0.83 0.8  0.76 0.8  0.83 0.88 0.85 0.73 0.77 0.81 0.78 0.84 0.94 0.76 0.89 0.96 0.94 0.87 0.85 0.83 0.82 0.87 0.86 0.87 0.9  0.26]\n",
            " [0.19 0.8  0.72 0.76 0.84 0.77 0.73 0.75 0.76 0.75 0.79 0.84 0.86 0.87 0.86 0.93 0.88 0.85 0.78 0.81 0.73 0.71 0.69 0.67 0.71 0.8  0.81 0.45]\n",
            " [0.   0.48 0.86 0.76 0.7  0.67 0.72 0.77 0.8  0.82 0.84 0.81 0.83 0.82 0.78 0.77 0.76 0.75 0.76 0.75 0.78 0.75 0.69 0.61 0.65 0.69 0.82 0.36]\n",
            " [0.   0.   0.29 0.74 0.83 0.75 0.69 0.67 0.69 0.71 0.73 0.74 0.74 0.74 0.76 0.78 0.8  0.82 0.82 0.82 0.83 0.74 0.74 0.76 0.75 0.85 0.67 0.  ]\n",
            " [0.01 0.   0.   0.   0.26 0.78 0.87 0.93 0.94 0.95 0.96 0.95 0.96 0.87 0.86 0.76 0.75 0.7  0.71 0.71 0.71 0.69 0.65 0.66 0.39 0.23 0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.16 0.24 0.17 0.28 0.16 0.14 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDUGq9V_YXS8"
      },
      "source": [
        "**Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coxbKBX1YXS8"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation='relu'), \n",
        "                                    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "model.compile(optimizer = tf.optimizers.Adam(), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWECVe-eYXS8"
      },
      "source": [
        "**Model Fitting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mDz4ZcNYXS8",
        "outputId": "45bb068a-87d2-48c4-941f-f62966b85725",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6352 - accuracy: 0.7799\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3873 - accuracy: 0.8622\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3445 - accuracy: 0.8760\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3125 - accuracy: 0.8859\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2928 - accuracy: 0.8906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfFCMBpjYXS8"
      },
      "source": [
        "**Evaluasi**\n",
        "\n",
        "Setelah proses model fitting, maka dilakukan evaluasi kinerja model terhadap datatest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7vBCVHcYXS9",
        "outputId": "ee11b2cb-32a5-49ef-b83b-d20accc0f9cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3593 - accuracy: 0.8716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3592548370361328, 0.8715999722480774]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVJHKLQEYXS9"
      },
      "source": [
        "**Visualisasikan Hasil Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfDM42RMYXS9",
        "outputId": "3cf44c43-6501-453d-af8a-e6bdf37c55f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCwbF2gMYXS9"
      },
      "source": [
        "Kedua grafik di atas menunjukkan performa model neural network terhadap hasil training. Semakin tinggi grafik Training Accuracy maka sepatutnya semakin baik performa modelnya saat training. Berbanding terbalik dengan Training Loss, jika grafiknya semakin menurun maka semakin baik performa trainingnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwqFrGNrYXS9"
      },
      "source": [
        "**Latihan 1**\n",
        "\n",
        "Jalankan kode program di bawah ini:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "zboynA_mYXS-",
        "outputId": "2ec65cd0-a588-4539-aced-25dcecf60efd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.7477834e-06 2.1829821e-06 8.8439663e-07 1.2558996e-07 5.3808426e-06 8.0379397e-02 3.9984261e-07 7.9622090e-02 2.4244480e-04 8.3974439e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGtgQtl7YXS-"
      },
      "source": [
        "**Apa arti angka dari output kode program di atas?**\n",
        "\n",
        "1.   10 nilai random yang tidak ada artinya\n",
        "2.   10 klasifikasi yang dihasilkan dari model\n",
        "3.   Nilai probabilitas dari setiap label\n",
        "\n",
        "\n",
        "Jawaban: (3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUeAud2-YXS-"
      },
      "source": [
        "**Latihan 2**\n",
        "\n",
        "Review kode program pendefinisian model yang telah kita lakukan di atas, kemudian kita ubah jumlah neurons pada hidden layer menjadi 512. Apakah terjadi perubahan pada nilai traning loss? Bagaimana menurut pendapat anda?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZJ5Tke_YXS-",
        "outputId": "5d208366-bbe8-48c0-f8ab-42bddf9ccf51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3426\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0812\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0482\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0341\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0266\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0865\n",
            "[3.80077775e-10 1.15026065e-10 2.58460892e-10 5.43339866e-06 1.92653163e-12 2.04241901e-10 9.96483864e-15 9.99994278e-01 5.62571725e-11 2.12839367e-07]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDGwxdMhYXS-"
      },
      "source": [
        "## Latihan 3: \n",
        "\n",
        "Bagaimana kalau kita menghilangkan layer **`Flatten()`**? Apa yang akan terjadi?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uObcLoVAYXS_",
        "outputId": "908ac48c-d3e5-489d-b610-3521aa39ab89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.models.Sequential([#tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2d213c0c41f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1569 sparse_categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4941 sparse_categorical_crossentropy\n        labels=target, logits=output)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py:4241 sparse_softmax_cross_entropy_with_logits_v2\n        labels=labels, logits=logits, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py:4156 sparse_softmax_cross_entropy_with_logits\n        logits.get_shape()))\n\n    ValueError: Shape mismatch: The shape of labels (received (32, 1)) should equal the shape of logits except for the last dimension (received (32, 28, 10)).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qq0ymmtYXS_"
      },
      "source": [
        "Anda mendapatkan error mengenai \"shape of the data\", artinya dimensi data tidak sama dengan dimensi input yang diterima oleh input layer pada model. Ingat kembali bahwa dataset yang kita gunakan adalah gambar dengan resolusi 28x28 pixel, maka kita harus membuat input layer yang bisa memfasilitasi hal tersebut (_membuat kode program untuk memfasilitasi input gambar 28x28 sangat kompleks_).\n",
        "\n",
        "Oleh karena itu, layer `Flatten()` berguna dalam hal mempermudah implementasi hal tersebut. Layer ini secara otomatis akan mengubah input 28x28 pixel menjadi array 1 dimensi sepanjang 748 (28 x 28 = 748)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7t8b8xxYXS_"
      },
      "source": [
        "**Latihan 4**:\n",
        "\n",
        "Bagaimana kalau kita ubah jumlah neurons pada output layer menjadi 5, apakah yang akan terjadi? Mengapa hal itu terjadi?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaHkG5v9YXS_",
        "outputId": "e8569cee-2c11-4827-c5e6-9caf727450ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(5, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: nan\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: nan\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: nan\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: nan\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: nan\n",
            "313/313 [==============================] - 1s 2ms/step - loss: nan\n",
            "[nan nan nan nan nan]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDfa5lhfYXS_"
      },
      "source": [
        "**Latihan 5**: \n",
        "\n",
        "Kita akan menambahkan hidden layer baru dengan jumlah neurons sebanyak 256. Apakah yang akan terjadi? Mengapa hal itu terjadi?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOUIl6xDYXTA",
        "outputId": "390e3cc7-6118-4685-b6f8-042fdff184c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(256, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3204\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0848\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0509\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0389\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0286\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0752\n",
            "[6.5174859e-11 1.1577314e-07 3.9136594e-08 1.1099228e-06 3.3990497e-10 2.2279878e-09 9.6004332e-15 9.9998641e-01 2.4425451e-09 1.2294991e-05]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW4QGGNzYXTA"
      },
      "source": [
        "**Latihan 6**: \n",
        "\n",
        "Cobalah untuk menambahkan jumlah epoch secara bertahap menjadi 15, 30, 50, kemudian 100. Apakah yang akan terjadi? Dan mengapa hal itu terjadi?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCIRa8CxYXTA",
        "outputId": "84ce6580-cec1-4dfc-c7c3-a1113634dce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=30)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3338\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0837\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0513\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0362\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0243\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0190\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0157\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0131\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0097\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0095\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0078\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0068\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0065\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0086\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0050\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0063\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0063\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0059\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0039\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0054\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0063\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0029\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0075\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0051\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0060\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0037\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0068\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0031\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0040\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0058\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1346\n",
            "[1.04499826e-35 3.45618517e-23 1.86951305e-17 7.50699323e-22 2.47479471e-32 2.18390363e-35 1.12357332e-34 1.00000000e+00 1.13461271e-26 7.84600070e-25]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QTXBRm2YXTA"
      },
      "source": [
        "**Latihan 7**: \n",
        "\n",
        "Jika kita menghilangkan proses preprocessing, apa yang akan terjadi? Apakah anda akan mendapatkan hasil yang berbeda? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7uonqoxYXTA",
        "outputId": "db04cbea-f3a5-4513-db61-d8836d2c2821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocessing\n",
        "# Berikan tag komentar pada baris kode program 6 dan 7\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3419\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0856\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0539\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0314\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0250\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0191\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0173\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0123\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0098\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0086\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0848\n",
            "[1.3703081e-17 7.2350692e-13 8.4751104e-09 7.7046792e-08 2.8730355e-17 3.6912063e-16 3.9372001e-19 9.9999988e-01 1.1356654e-10 6.0406981e-14]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}