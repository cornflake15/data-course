{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementasi algoritma Artificial Neural Network menggunakan Keras dan Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "y = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 38.8404\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 30.9080\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.6599\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.7372\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 15.8574\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.7981\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3846\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4793\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9740\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2012aa78970>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.837426]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[3, 5], [5, 1], [10, 2], [3, 2], [4, 3], [6, 7], [8, 10]])\n",
    "y = np.array([75, 82, 93, 60, 63, 94, 97])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "y_scale = scaler.fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(2, input_shape=(2,)),\n",
    "    keras.layers.Dense(1, activation='sigmoid'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6662.6992\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6303.4062\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5840.4346\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 991us/step - loss: 5397.8857\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 983us/step - loss: 4990.0322\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4614.1548\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 970us/step - loss: 4267.7461\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3948.4956\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3654.2742\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3383.1199\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3133.2241\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2902.9199\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2690.6719\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2495.0642\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2314.7917\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2148.6533\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1995.5397\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 992us/step - loss: 1854.4297\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1724.3834\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1604.5323\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 994us/step - loss: 1494.0780\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1392.2830\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 995us/step - loss: 1298.4686\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1212.0098\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1132.3290\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1058.8951\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 982us/step - loss: 991.2186\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 976us/step - loss: 928.8481\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 871.3669\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 818.3926\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 769.5716\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 724.5778\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 992us/step - loss: 683.1118\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 644.8964\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 609.6774\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 577.2196\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 547.3063\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 519.7383\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 494.3315\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 470.9167\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 449.3376\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 429.4504\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 411.1224\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 394.2312\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 378.6642\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 364.3176\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 976us/step - loss: 351.0959\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 338.9108\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 327.6809\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 317.3315\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 307.7935\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 996us/step - loss: 299.0034\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 290.9023\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 991us/step - loss: 283.4363\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 276.5557\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 270.2145\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 264.3704\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 258.9846\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 254.0210\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 249.4465\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 245.2307\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 241.3455\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 237.7648\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 234.4647\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 231.4235\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 996us/step - loss: 228.6207\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 226.0376\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 223.6571\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 221.4632\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 219.4412\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 217.5779\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 215.8605\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 214.2779\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 212.8193\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 211.4751\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 210.2363\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 209.0946\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 208.0423\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 207.0726\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 206.1789\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 205.3554\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 204.5963\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 203.8967\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 203.2520\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 982us/step - loss: 202.6578\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 202.1102\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 201.6056\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 201.1405\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 200.7119\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 200.3169\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 199.9529\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 984us/step - loss: 199.6174\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 199.3081\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 199.0232\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 198.7605\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 198.5185\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 198.2955\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 198.0899\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 197.9005\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 197.7258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 197.5649\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 197.4167\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 197.2800\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 197.1540\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 197.0380\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 196.9310\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 196.8324\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 196.7415\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 196.6578\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 196.5806\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 196.5095\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 196.4440\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 196.3835\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 196.3279\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 984us/step - loss: 196.2766\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 996us/step - loss: 196.2293\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 993us/step - loss: 196.1857\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 196.1455\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 196.1085\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 196.0744\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 196.0430\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 993us/step - loss: 196.0141\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 195.9873\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 195.9627\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.9400\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.9192\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 984us/step - loss: 195.8999\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 986us/step - loss: 195.8822\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 195.8657\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 195.8507\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.8368\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.8240\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.8122\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.8013\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 195.7913\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.7821\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.7735\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.7657\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.7584\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 195.7518\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.7456\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 195.7400\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 195.7348\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.7300\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.7256\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.7215\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.7177\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 195.7142\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.7110\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.7080\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.7053\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 195.7029\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.7005\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6985\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6964\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 195.6947\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6930\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.6914\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6900\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.6887\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6876\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 988us/step - loss: 195.6864\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6854\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6845\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 195.6836\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 195.6828\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 982us/step - loss: 195.6821\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 985us/step - loss: 195.6814\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6808\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 195.6802\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.6797\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6792\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6787\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 195.6783\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.6780\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 195.6776\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 984us/step - loss: 195.6772\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 195.6769\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.6767\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 195.6764\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6762\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 195.6760\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 993us/step - loss: 195.6758\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6756\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.6755\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6753\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 195.6752\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 996us/step - loss: 195.6750\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.6749\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6748\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6746\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.6746\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6745\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.6744\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.6743\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6743\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 195.6742\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 195.6741\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 195.6741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 195.6740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2012d9170d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79.233864]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([[5, 5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh 2\n",
    "# Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(training_images[0])\n",
    "print(training_labels[0])\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.         0.         0.05098039 0.28627451\n",
      "  0.         0.         0.00392157 0.01568627 0.         0.         0.         0.         0.00392157 0.00392157 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01176471 0.         0.14117647 0.53333333 0.49803922\n",
      "  0.24313725 0.21176471 0.         0.         0.         0.00392157 0.01176471 0.01568627 0.         0.         0.01176471]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.4        0.8        0.69019608\n",
      "  0.5254902  0.56470588 0.48235294 0.09019608 0.         0.         0.         0.         0.04705882 0.03921569 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.60784314 0.9254902  0.81176471\n",
      "  0.69803922 0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608 0.30196078 0.50980392 0.28235294 0.05882353]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.         0.27058824 0.81176471 0.8745098  0.85490196\n",
      "  0.84705882 0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902 0.55294118 0.34509804 0.6745098  0.25882353]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.00392157 0.00392157 0.         0.78431373 0.90980392 0.90980392 0.91372549\n",
      "  0.89803922 0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922 0.48235294 0.76862745 0.89803922 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.71764706 0.88235294 0.84705882 0.8745098\n",
      "  0.89411765 0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667 0.8745098  0.96078431 0.67843137 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.75686275 0.89411765 0.85490196 0.83529412\n",
      "  0.77647059 0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098  0.8627451  0.95294118 0.79215686 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.01176471 0.         0.04705882 0.85882353 0.8627451  0.83137255 0.85490196\n",
      "  0.75294118 0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255 0.88627451 0.77254902 0.81960784 0.20392157]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.38823529 0.95686275 0.87058824 0.8627451  0.85490196\n",
      "  0.79607843 0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451  0.96078431 0.46666667 0.65490196 0.21960784]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01568627 0.         0.         0.21568627 0.9254902  0.89411765 0.90196078 0.89411765\n",
      "  0.94117647 0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039 0.85098039 0.81960784 0.36078431 0.        ]\n",
      " [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098 0.00784314 0.         0.         0.         0.         0.         0.92941176 0.88627451 0.85098039 0.8745098  0.87058824\n",
      "  0.85882353 0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725 0.85490196 1.         0.30196078 0.        ]\n",
      " [0.         0.01176471 0.         0.         0.         0.         0.         0.         0.         0.24313725 0.56862745 0.8        0.89411765 0.81176471 0.83529412 0.86666667 0.85490196\n",
      "  0.81568627 0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725 0.87843137 0.95686275 0.62352941 0.        ]\n",
      " [0.         0.         0.         0.         0.07058824 0.17254902 0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824 0.85098039 0.88627451 0.78431373 0.80392157 0.82745098\n",
      "  0.90196078 0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902 0.91372549 0.93333333 0.84313725 0.        ]\n",
      " [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667 0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784 0.78431373 0.62352941 0.96078431 0.75686275 0.80784314\n",
      "  0.8745098  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098 0.8627451  0.90980392 0.96470588 0.        ]\n",
      " [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098 0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451  0.94117647 0.31372549 0.58823529 1.         0.89803922\n",
      "  0.86666667 0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784 0.87058824 0.89411765 0.88235294 0.        ]\n",
      " [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922 0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725 0.85098039 0.94509804 0.25490196 0.28627451 0.41568627\n",
      "  0.45882353 0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098  0.8745098  0.87843137 0.89803922 0.11372549]\n",
      " [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157 0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314 0.77647059 0.83529412 0.94117647 0.76470588 0.89019608\n",
      "  0.96078431 0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824 0.8627451  0.86666667 0.90196078 0.2627451 ]\n",
      " [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902 0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569 0.85882353 0.86666667 0.8627451  0.9254902  0.88235294\n",
      "  0.84705882 0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098  0.70980392 0.80392157 0.80784314 0.45098039]\n",
      " [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824 0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471 0.82745098 0.82352941 0.78431373 0.76862745 0.76078431\n",
      "  0.74901961 0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471 0.65490196 0.69411765 0.82352941 0.36078431]\n",
      " [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961 0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549  0.74117647 0.7372549  0.75686275 0.77647059 0.8\n",
      "  0.81960784 0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431 0.75294118 0.84705882 0.66666667 0.        ]\n",
      " [0.00784314 0.         0.         0.         0.25882353 0.78431373 0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118 0.95686275 0.86666667 0.8627451  0.75686275 0.74901961\n",
      "  0.70196078 0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353 0.38823529 0.22745098 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431 0.1372549  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Print\n",
    "plt.imshow(training_images[0])\n",
    "print(training_labels[0])\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation='relu'), \n",
    "                                    tf.keras.layers.Dense(10, activation='softmax')])\n",
    "model.compile(optimizer = tf.optimizers.Adam(), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5055 - accuracy: 0.8231\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3785 - accuracy: 0.8642\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3393 - accuracy: 0.8756\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3178 - accuracy: 0.8834\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2981 - accuracy: 0.8903: 0s - l\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3518 - accuracy: 0.8740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3518073856830597, 0.8740000128746033]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.1416594e-05 7.4146931e-07 1.9706975e-05 7.6855412e-07 1.0854161e-05 3.2612927e-02 2.3008796e-04 2.1580902e-01 3.8986764e-04 7.5085455e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this list represent?\n",
    "\n",
    "\n",
    "1.   It's 10 random meaningless values\n",
    "2.   It's the first 10 classifications that the computer made\n",
    "3.   It's the probability that this item is each of the 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer: \n",
    "The correct answer is (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do you know that this list tells you that the item is an ankle boot?\n",
    "\n",
    "\n",
    "1.   There's not enough information to answer that question\n",
    "2.   The 10th element on the list is the biggest, and the ankle boot is labelled 9\n",
    "2.   The ankle boot is label 9, and there are 0->9 elements in the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Answer\n",
    "The correct answer is (2). Both the list and the labels are 0 based, so the ankle boot having label 9 means that it is the 10th of the 10 classes. The list having the 10th element being the highest value means that the Neural Network has predicted that the item it is classifying is most likely an ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exercise 2: \n",
    "Let's now look at the layers in your model. Experiment with different values for the dense layer with 512 neurons. What different results do you get for loss, training time etc? Why do you think that's the case? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exercise 3: \n",
    "\n",
    "What would happen if you remove the Flatten() layer. Why do you think that's the case? \n",
    "\n",
    "You get an error about the shape of the data. It may seem vague right now, but it reinforces the rule of thumb that the first layer in your network should be the same shape as your data. Right now our data is 28x28 images, and 28 layers of 28 neurons would be infeasible, so it makes more sense to 'flatten' that 28,28 into a 784x1. Instead of wriitng all the code to handle that ourselves, we add the Flatten() layer at the begining, and when the arrays are loaded into the model later, they'll automatically be flattened for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([#tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exercise 4: \n",
    "\n",
    "Consider the final (output) layers. Why are there 10 of them? What would happen if you had a different amount than 10? For example, try training the network with 5\n",
    "\n",
    "You get an error as soon as it finds an unexpected value. Another rule of thumb -- the number of neurons in the last layer should match the number of classes you are classifying for. In this case it's the digits 0-9, so there are 10 of them, hence you should have 10 neurons in your final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exercise 5: \n",
    "\n",
    "Consider the effects of additional layers in the network. What will happen if you add another layer between the one with 512 and the final layer with 10. \n",
    "\n",
    "Ans: There isn't a significant impact -- because this is relatively simple data. For far more complex data (including color images to be classified as flowers that you'll see in the next lesson), extra layers are often necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exercise 6: \n",
    "\n",
    "Consider the impact of training for more or less epochs. Why do you think that would be the case? \n",
    "\n",
    "Try 15 epochs -- you'll probably get a model with a much better loss than the one with 5\n",
    "Try 30 epochs -- you might see the loss value stops decreasing, and sometimes increases. This is a side effect of something called 'overfitting' which you can learn about [somewhere] and it's something you need to keep an eye out for when training neural networks. There's no point in wasting your time training if you aren't improving your loss, right! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=30)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[34])\n",
    "print(test_labels[34])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exercise 7: \n",
    "\n",
    "Before you trained, you normalized the data, going from values that were 0-255 to values that were 0-1. What would be the impact of removing that? Here's the complete code to give it a try. Why do you think you get different results? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "model.evaluate(test_images, test_labels)\n",
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bitf33250e8650946d19caa144309e3c9fe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
